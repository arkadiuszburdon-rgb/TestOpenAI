import asyncio, json, sounddevice as sd, websockets, os, time ,base64 ,wave
from dotenv import load_dotenv
from openai import OpenAI
import numpy as np

"""
Projekt: Klasyfikator obiekcji w czasie rzeczywistym podczas rozmowy telefonicznej.
Opis: Ten skrypt nasÅ‚uchuje mikrofonu, wykrywa mowÄ™ i wysyÅ‚a audio do OpenAI Realtime API.
Model analizuje wypowiedzi klientÃ³w i klasyfikuje je wedÅ‚ug predefiniowanych obiekcji sprzedaÅ¼owych.
Model: gpt-realtime-2025-08-28
"""


load_dotenv()
API_KEY = os.getenv("OPENAI_API_KEY")
#MODEL = "gpt-4o-realtime-preview-2024-12-17"
MODEL = "gpt-realtime-2025-08-28"
SAMPLE_RATE = 16000

RolaKwalifikator2 = """
Rola:

JesteÅ› agentem klasyfikujÄ…cym tekst.  Twoim zadaniem jest przypisaÄ‡ kaÅ¼dy otrzymany tekst do jednej z predefiniowanych obiekcji.
Kwalifikowane teksty pochodzÄ… od klientÃ³w podczas rozmÃ³w telefonicznych dotyczÄ…cych sprzedaÅ¼y produktÃ³w lub usÅ‚ug.
Kwalifikujesz wypowiedzi klientÃ³w, ktÃ³re mogÄ… zawieraÄ‡ obiekcje lub dane osobowe.
Kwalifikowane teksty sÄ… krÃ³tkie, zwykle jedno- lub dwuzdaniowe.
Kwalifikowane teksty sÄ… wyÅ‚Ä…cznie w jÄ™zyku polskim.
Zoptymalizuj swoje dziaÅ‚anie uwzglÄ™dniajÄ…c fakt, Å¼e teksty sÄ… wyÅ‚Ä…cznie w jÄ™zyku polskim.

Zasady:
- 
- Po "Start kwalifikacji": odpisz dokÅ‚adnie "Gotowy".
- Po "Start kwalifikacji": nie odpowiadaj, oczekuj tekstu do klasyfikacji.
- Po "Stop kwalifikacji": zakoÅ„cz pracÄ™ jako agent klasyfikujÄ…cy i wrÃ³Ä‡ do normalnego trybu.
- BezwzglÄ™dnie trzymaj siÄ™ zasad.

Format odpowiedzi dla kaÅ¼dego tekstu:
Obiekcja: [nazwa obiekcji]
Plik: [przypisany plik]
Klasyfikowany tekst: [oryginalny tekst]
Dodatkowo: wypeÅ‚nij tylko jeÅ›li opis obiekcji wymaga tej informacji; w przeciwnym razie pozostaw puste.

Zestaw obiekcji:

OBIEKCJA: Brak zainteresowania
PLIK: brak_zainteresowania.wav
OPIS: Klient nie jest zainteresowany rozmowÄ…, produktem lub ofertÄ….
PRZYKÅADY:
- "Nie jestem zainteresowany."
- "DziÄ™kujÄ™, ale nie potrzebujÄ™ tego."
- "ProszÄ™ nie dzwoniÄ‡ wiÄ™cej."

OBIEKCJA: Brak czasu
PLIK: brak_czasu.wav
OPIS: Klient twierdzi, Å¼e nie ma czasu na rozmowÄ™ lub decyzjÄ™.
PRZYKÅADY:
- "Nie mam teraz czasu, oddzwoniÄ™ pÃ³Åºniej."
- "ZajmujÄ™ siÄ™ czymÅ› innym, proszÄ™ zadzwoniÄ‡ jutro."
- "Nie mogÄ™ teraz rozmawiaÄ‡."

OBIEKCJA: Nie ufam
PLIK: nieufam.wav
OPIS: Klient wyraÅ¼a brak zaufania do procesu sprzedaÅ¼y lub handlowca.
PRZYKÅADY:
- "Nie wierzÄ™ w takie oferty."
- "JuÅ¼ raz siÄ™ naciÄ…Å‚em, nie dziÄ™kujÄ™."
- "Nie ufam sprzedawcom przez telefon."

OBIEKCJA: Za drogo
PLIK: zadrogo.wav
OPIS: Klient uwaÅ¼a, Å¼e cena jest zbyt wysoka lub nieadekwatna do wartoÅ›ci.
PRZYKÅADY:
- "Za drogie, nie staÄ‡ mnie."
- "U konkurencji jest taniej."
- "To nie jest warte takiej ceny."

OBIEKCJA: Nierozpoznany
PLIK: nierozpoznany.wav
OPIS: WypowiedÅº klienta nie pasuje jednoznacznie do Å¼adnej kategorii obiekcji lub jest nie na temat.
PRZYKÅADY:
- "Åadna pogoda."
- "Nie wiem, muszÄ™ siÄ™ zastanowiÄ‡."
- "Trudno mi powiedzieÄ‡."
- "To zaleÅ¼y, muszÄ™ porozmawiaÄ‡ z kimÅ› innym."

OBIEKCJA: Dane osobowe
PLIK: dane_osobowe.wav
OPIS: Klient przedstawia siÄ™ podajÄ…c imiÄ™ lub nazwisko.
DODATKOWO: W tym polu umieÅ›Ä‡ tylko rozpoznane imiÄ™ i nazwisko.
PRZYKÅADY:
- "Arkadiusz Burdon."
- "ImiÄ™ to bÄ™dzie Zenon."
- "Moje nazwisko to DzierÅ¼yÅ„ski."
- "No dobrze. To bÄ™dzie Feliks Amatorski"

OBIEKCJA: Dane adresowe
PLIK: dane_adresowe.wav
OPIS: Klient podaÅ‚ dane adresowe np. ulicÄ™, miejscowoÅ›Ä‡, kod pocztowy.
PRZYKÅADY:
- "Jestem z Legionowa."
- "Mieszka w Warszawie na ulicy GÃ³rnoÅ›lÄ…skiej."
- "To bÄ™dzie KrakÃ³w."

Start kwalifikacji
"""


def wav_writer(filename="mic_test.wav", sample_rate=16000):
    wf = wave.open(filename, 'wb')
    wf.setnchannels(1)        # mono
    wf.setsampwidth(2)        # 16-bit PCM = 2 bytes
    wf.setframerate(sample_rate)
    return wf

def is_voice(pcm, threshold=500):
    # konwersja bajtÃ³w do tablicy int16
    audio = np.frombuffer(pcm, dtype=np.int16)
    # energia sygnaÅ‚u
    energy = np.mean(np.abs(audio))
    #print(f"Energy: {energy}")
    return energy > threshold

async def run():
    
    print("ðŸŽ¤ Start â€” mÃ³w")
    
    wav = wav_writer()

    ws = await websockets.connect(
        f"wss://api.openai.com/v1/realtime?model={MODEL}",
        extra_headers={
            "Authorization": f"Bearer {API_KEY}",
            "OpenAI-Beta": "realtime=v1"  # âœ… TO JEST KLUCZ
        },
        max_size=None
    )

    print("âœ… PoÅ‚Ä…czono z Realtime API")
    
    
    

    # âœ… wymagane przez TwojÄ… wersjÄ™ API
    await ws.send(json.dumps({
        "type": "session.update",
        "session": {
            "modalities": ["audio", "text"],      # streaming audio IN
            "instructions": RolaKwalifikator2,
            "input_audio_format": "pcm16",  # najwaÅ¼niejsze!
            "output_audio_format": "pcm16",
            "turn_detection": None         # bez auto-VAD (na razie)
        }
    }))
    
    

    CHUNK = 2048
    pending = False
    buffer_ms = 0

    async def mic():
        nonlocal pending, buffer_ms
        talking = False
        silence_frames = 0
        has_voice_data = False  # âœ… nowa flaga: czy mikrofon daÅ‚ juÅ¼ gÅ‚os

        with sd.RawInputStream(samplerate=SAMPLE_RATE, channels=1, dtype="int16") as stream:
            while True:
                data, _ = stream.read(CHUNK)
                pcm = bytes(data)

                # zapis WAV
                wav.writeframes(pcm)

                # VAD: czy jest mowa?
                voice = is_voice(pcm)

                if voice:
                    talking = True
                    silence_frames = 0
                    has_voice_data = True  # âœ… pierwszy gÅ‚os siÄ™ pojawiÅ‚
                else:
                    if talking:
                        silence_frames += 1

                # wysyÅ‚amy audio tylko jeÅ›li juÅ¼ byÅ‚ gÅ‚os
                if has_voice_data and (talking or silence_frames < 5):
                    # wysyÅ‚amy audio chunk
                    await ws.send(json.dumps({
                        "type": "input_audio_buffer.append",
                        "audio": base64.b64encode(pcm).decode("utf-8")
                    }))
                    buffer_ms += (len(pcm) / 2 / SAMPLE_RATE) * 1000

                # â›” nie commituj, jeÅ›li NIE byÅ‚o mowy
                if not has_voice_data:
                    await asyncio.sleep(0.001)
                    continue

                # âœ… commit TYLKO gdy:
                # - mÃ³wiliÅ›my
                # - jest kilka ramek ciszy
                # - mamy >120 ms audio
                # - model nie jest zajÄ™ty odpowiedziÄ…
                if talking and silence_frames >= 5 and buffer_ms > 120 and not pending:
                    print("\n--- Committing buffer ---\n")
                    await ws.send(json.dumps({"type": "input_audio_buffer.commit"}))
                    await ws.send(json.dumps({
                        "type": "response.create",
                        "response": {
                            "modalities": ["text"]
                        }
                    }))
                    pending = True
                    buffer_ms = 0.0
                    talking = False
                    has_voice_data = False  # âœ… poczekamy na kolejne zdanie

                await asyncio.sleep(0.001)



    async def rx():
        nonlocal pending
        async for msg in ws:
            evt = json.loads(msg)
            t = evt.get("type")
            
            
            #if "text" in evt:
            #    print(f"{t} - TEXT EVENT RAW:", evt)


            # ===========================
            # LOG WSZYSTKIE EVENTY
            # ===========================
            # UWAGA â€” NIE PRINTUJ TEKSTU TUTAJ
            #print(f"[EVENT] {t}")

            # ===========================
            # STREAMOWANIE TEKSTU
            # ===========================
            if t == "response.text.delta":
                if "text" in evt:
                    print(evt["text"], end="", flush=True)
                continue

            # gÅ‚Ã³wne miejsce odbioru tekstu
            elif t == "response.text.done":
                print(evt.get("text", ""))
                print("\n---\n")
                pending = False
                await ws.send(json.dumps({"type": "session.reset"}))
                continue


    await asyncio.gather(mic(), rx())
 
from openai import OpenAI

client = OpenAI(api_key=API_KEY)

models = client.models.list()

for m in models.data:
    print(m.id)


asyncio.run(run())
