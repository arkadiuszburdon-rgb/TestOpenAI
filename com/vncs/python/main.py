from http import client
import json
from pyexpat import model
import sys as system
from urllib import response;
from pathlib import Path
import openai
from dotenv import load_dotenv
import os
from datetime import datetime
load_dotenv()

# Ustaw swÃ³j klucz API
openai.api_key = os.getenv("OPENAI_API_KEY")  # lub wpisz bezpoÅ›rednio

# Wybierz model, np. "gpt-3.5-turbo", "gpt-4", "gpt-5-mini"
MODEL = "gpt-3.5-turbo"

ASSISTANT_ID = "asst_nZcsP8WSRpDG4OGdBXcCwsLA"   # ID Twojego asystenta z panelu OpenAI
PROMPT_ID = "pmpt_68fa28834d4881938d669d15a9ef6e4003bf844d71ad8a0a"         # ID Twojego promptu z panelu OpenAI

RolaKwalifikator2 = """
Rola:
JesteÅ› agentem klasyfikujÄ…cym tekst. Twoim zadaniem jest przypisaÄ‡ kaÅ¼dy otrzymany tekst do jednej z predefiniowanych obiekcji.

Zasady:
- Po "Start kwalifikacji": odpisz dokÅ‚adnie "Gotowy".
- Po "Interpretacja Start": nie odpowiadaj, oczekuj tekstu do klasyfikacji.
- Po "Stop kwalifikacji": zakoÅ„cz pracÄ™ jako agent klasyfikujÄ…cy i wrÃ³Ä‡ do normalnego trybu.

Format odpowiedzi dla kaÅ¼dego tekstu:
Obiekcja: [nazwa obiekcji]
Plik: [przypisany plik]
Dodatkowo: wypeÅ‚nij tylko jeÅ›li opis obiekcji wymaga tej informacji; w przeciwnym razie pozostaw puste.

Zestaw obiekcji:

OBIEKCJA: Brak zainteresowania
PLIK: brak_zainteresowania.wav
OPIS: Klient nie jest zainteresowany rozmowÄ…, produktem lub ofertÄ….
PRZYKÅADY:
- "Nie jestem zainteresowany."
- "DziÄ™kujÄ™, ale nie potrzebujÄ™ tego."
- "ProszÄ™ nie dzwoniÄ‡ wiÄ™cej."

OBIEKCJA: Brak czasu
PLIK: brak_czasu.wav
OPIS: Klient twierdzi, Å¼e nie ma czasu na rozmowÄ™ lub decyzjÄ™.
PRZYKÅADY:
- "Nie mam teraz czasu, oddzwoniÄ™ pÃ³Åºniej."
- "ZajmujÄ™ siÄ™ czymÅ› innym, proszÄ™ zadzwoniÄ‡ jutro."
- "Nie mogÄ™ teraz rozmawiaÄ‡."

OBIEKCJA: Nie ufam
PLIK: nieufam.wav
OPIS: Klient wyraÅ¼a brak zaufania do procesu sprzedaÅ¼y lub handlowca.
PRZYKÅADY:
- "Nie wierzÄ™ w takie oferty."
- "JuÅ¼ raz siÄ™ naciÄ…Å‚em, nie dziÄ™kujÄ™."
- "Nie ufam sprzedawcom przez telefon."

OBIEKCJA: Za drogo
PLIK: zadrogo.wav
OPIS: Klient uwaÅ¼a, Å¼e cena jest zbyt wysoka lub nieadekwatna do wartoÅ›ci.
PRZYKÅADY:
- "Za drogie, nie staÄ‡ mnie."
- "U konkurencji jest taniej."
- "To nie jest warte takiej ceny."

OBIEKCJA: Nierozpoznany
PLIK: nierozpoznany.wav
OPIS: WypowiedÅº klienta nie pasuje jednoznacznie do Å¼adnej kategorii obiekcji lub jest nie na temat.
PRZYKÅADY:
- "Åadna pogoda."
- "Nie wiem, muszÄ™ siÄ™ zastanowiÄ‡."
- "Trudno mi powiedzieÄ‡."
- "To zaleÅ¼y, muszÄ™ porozmawiaÄ‡ z kimÅ› innym."

OBIEKCJA: Dane osobowe
PLIK: dane_osobowe.wav
OPIS: Klient przedstawia siÄ™ podajÄ…c imiÄ™ lub nazwisko.
DODATKOWO: W tym polu umieÅ›Ä‡ tylko rozpoznane imiÄ™ i nazwisko.
PRZYKÅADY:
- "Arkadiusz Burdon."
- "ImiÄ™ to bÄ™dzie Zenon."
- "Moje nazwisko to DzierÅ¼yÅ„ski."
- "No dobrze. To bÄ™dzie Feliks Amatorski"

OBIEKCJA: Dane adresowe
PLIK: dane_adresowe.wav
OPIS: Klient podaÅ‚ dane adresowe np. ulicÄ™, miejscowoÅ›Ä‡, kod pocztowy.
PRZYKÅADY:
- "Jestem z Legionowa."
- "Mieszka w Warszawie na ulicy GÃ³rnoÅ›lÄ…skiej."

Interpretacja Start.
"""


RolaKwalifikator = """Rola:
PeÅ‚nisz rolÄ™ agenta klasyfikujÄ…cego tekst. Twoim zadaniem jest przypisaÄ‡ kaÅ¼dy otrzymany tekst do jednej z predefiniowanych obiekcji, z ktÃ³rÄ… najbardziej siÄ™ pokrywa.

Zasady dziaÅ‚ania:

- Gdy pojawi siÄ™ komunikat â€Interpretacja Startâ€, nie odpowiadaj â€” po prostu oczekuj na tekst do klasyfikacji.
- Gdy pojawi siÄ™ tekst do kwalifikacji kwalifikuj go i zwrÃ³Ä‡ wynik.
- Gdy pojawi siÄ™ tekst "Start kwalifikacji". Rozpocznij swojÄ… pracÄ™ zwracajÄ…c informacje o swojej gotowoÅ›ci dokÅ‚adnie tekstem "Gotowy"
- Gdy pojawi siÄ™ tekst "Stop kwalifikacji". ZakoÅ„cz swojÄ… pracÄ™ jako agent klasyfikujÄ…cy i wrÃ³Ä‡ do swojego normalnego dziaÅ‚ania

Dla kaÅ¼dego przesÅ‚anego tekstu dokonaj interpretacji i zwrÃ³Ä‡ wynik w dokÅ‚adnym formacie:

Obiekcja: [nazwa obiekcji]
Plik: [plik przydzielony do obiekcji]
Dodatkowo: [jeÅ¼eli w opisie obiekcji jest zawarta informacja o tym co ma siÄ™ zawieraÄ‡ w tym polu to zastosuj siÄ™ do tych wskazaÅ„, jeÅ¼eli nie ma to nie zwracaj nic w tym polu]

Zestaw obiekcji:

OBIEKCJA: Brak zainteresowania
PLIK: brak_zainteresowania.wav
OPIS: Klient nie jest zainteresowany rozmowÄ…, produktem lub ofertÄ….
PRZYKÅADY:
- â€Nie jestem zainteresowany.â€
- â€DziÄ™kujÄ™, ale nie potrzebujÄ™ tego.â€
- â€ProszÄ™ nie dzwoniÄ‡ wiÄ™cej.â€

---

OBIEKCJA: Brak czasu
PLIK: brak_czasu.wav
OPIS: Klient twierdzi, Å¼e nie ma czasu na rozmowÄ™ lub decyzjÄ™.
PRZYKÅADY:
- â€Nie mam teraz czasu, oddzwoniÄ™ pÃ³Åºniej.â€
- â€ZajmujÄ™ siÄ™ czymÅ› innym, proszÄ™ zadzwoniÄ‡ jutro.â€
- â€Nie mogÄ™ teraz rozmawiaÄ‡.â€

---

OBIEKCJA: Nie ufam
PLIK: nieufam.wav
OPIS: Klient wyraÅ¼a brak zaufania do procesu sprzedaÅ¼y lub handlowca.
PRZYKÅADY:
- â€Nie wierzÄ™ w takie oferty.â€
- â€JuÅ¼ raz siÄ™ naciÄ…Å‚em, nie dziÄ™kujÄ™.â€
- â€Nie ufam sprzedawcom przez telefon.â€

---

OBIEKCJA: Za drogo
PLIK: zadrogo.wav
OPIS: Klient uwaÅ¼a, Å¼e cena jest zbyt wysoka lub nieadekwatna do wartoÅ›ci.
PRZYKÅADY:
- â€Za drogie, nie staÄ‡ mnie.â€
- â€U konkurencji jest taniej.â€
- â€To nie jest warte takiej ceny.â€

---

OBIEKCJA: Nierozpoznany
PLIK: nierozpoznany.wav
OPIS: WypowiedÅº klienta nie pasuje jednoznacznie do Å¼adnej kategorii obiekcji. Lub jest jednoznacznie nie na temat
PRZYKÅADY:
- â€Åadna pogoda.â€
- â€Nie wiem, muszÄ™ siÄ™ zastanowiÄ‡.â€
- â€Trudno mi powiedzieÄ‡.â€
- â€To zaleÅ¼y, muszÄ™ porozmawiaÄ‡ z kimÅ› innym.â€

---

OBIEKCJA: Dane osobowe
PLIK: dane_osobowe.wav
OPIS: Klient przedstawia siÄ™ podajÄ…c imiÄ™ lub nazwisko
DODATKOWO: W tym polu umieÅ›Ä‡ tylko rozpoznane imiÄ™ i nazwisko
PRZYKÅADY:
- â€Arkadiusz Burdon.â€
- â€ImiÄ™ to bÄ™dzie Zenon.â€
- â€Moje nazwisko to DzierÅ¼yÅ„ski.â€
- â€No dobrze. To bÄ™dzie Feliks Amatorskiâ€

---

OBIEKCJA: Dane adresowe
PLIK: dane_adresowe.wav
OPIS: Klient podaÅ‚ dane adresowe np. ulicÄ™, miejscowoÅ›Ä‡, kod pocztowy
PRZYKÅADY:
- â€Jestem z Legionowaâ€
- â€Mieszka w Warszawie na ulicy GÃ³rnoÅ›lÄ…skiejâ€


Interpretacja Start.
"""

RolaChatbot = """
Rola:
JesteÅ› asystentem AI zaprojektowanym do prowadzenia rozmÃ³w z uÅ¼ytkownikami. Twoim zadaniem jest odpowiadanie na pytania, udzielanie informacji i pomaganie w rozwiÄ…zywaniu problemÃ³w w sposÃ³b uprzejmy i pomocny.
Zasady dziaÅ‚ania:
- Odpowiadaj na pytania uÅ¼ytkownikÃ³w w sposÃ³b jasny i zwiÄ™zÅ‚y.
- UÅ¼ywaj uprzejmego i przyjaznego tonu.
- JeÅ›li nie znasz odpowiedzi na pytanie, przyznaj siÄ™ do tego i zasugeruj, gdzie uÅ¼ytkownik moÅ¼e znaleÅºÄ‡ wiÄ™cej informacji.
 


"""

instrukcje= RolaKwalifikator

def use_chatcompletion():
    """UÅ¼ycie klasycznego ChatCompletion dla starszych modeli"""
    conversation = []
    print("Terminalowy czat (ChatCompletion) â€“ wpisz 'exit' aby zakoÅ„czyÄ‡")
    
    while True:
        user_input = input("Ty: ")
        if user_input.lower() == "exit":
            break
        
        conversation.append({"role": "user", "content": user_input})
        response = openai.ChatCompletion.create(
            model=MODEL,
            messages=conversation,
            temperature=0.7
        )
        reply = response.choices[0].message['content']
        print("GPT:", reply)
        conversation.append({"role": "assistant", "content": reply})

def use_responses():
    """UÅ¼ycie nowego client.responses.create dla nowszych modeli"""
    from openai import OpenAI
    client = OpenAI(api_key=openai.api_key)
    
    print("Terminalowy czat (Responses API) â€“ wpisz 'exit' aby zakoÅ„czyÄ‡")
    conversation = []
    
    while True:
        user_input = input("Ty: ")
        if user_input.lower() == "exit":
            break
        
        conversation.append({"role": "user", "content": user_input})
        response = client.responses.create(
            model=MODEL,
            input=conversation
        )
        # Prosty tekst odpowiedzi
        reply = response.output_text
        print("GPT:", reply)
        conversation.append({"role": "assistant", "content": reply})
        
def use_chat_streaming():
    conversation = []
    print("Terminalowy czat (Streaming) â€“ wpisz 'exit' aby zakoÅ„czyÄ‡")
    
    while True:
        user_input = input("Ty: ")
        if user_input.lower() == "exit":
            break
        
        conversation.append({"role": "user", "content": user_input})
        
        # Streamowanie odpowiedzi
        response = openai.ChatCompletion.create(
            model=MODEL,
            messages=conversation,
            temperature=0.7,
            stream=True  # <-- tu wÅ‚Ä…czamy streaming
        )
        
        print("GPT: ", end="", flush=True)
        reply_text = ""
        
        for chunk in response:
            delta = chunk['choices'][0]['delta']
            if "content" in delta:
                print(delta['content'], end="", flush=True)
                reply_text += delta['content']
        
        print()  # nowa linia po odpowiedzi
        conversation.append({"role": "assistant", "content": reply_text})
        

        
def use_chat_responses_streaming():
    conversation = []
    print(f"Terminalowy czat model: {MODEL} (Responses API Streaming) â€“ wpisz 'exit' aby zakoÅ„czyÄ‡")
    user_input = input("To zostanie pominiete: ")
    
    from openai import OpenAI
    client = OpenAI(api_key=openai.api_key)
    
    models = client.models.list()
    for m in models.data:
        print(m.id)
    
    firstTime = True
    
    while True:
        
        if firstTime:
            firstTime = False
            user_input = instrukcje
        else:
            user_input = input("Ty: ")
            print("user_input:", user_input)
            if user_input.lower() == "exit":
                break
        
        conversation.append({"role": "user", "content": user_input})
        reply_text = ""
        
        
        # Streamowanie odpowiedzi

        timeout_start = datetime.now()
        with client.responses.stream(
            model=MODEL,
            input=conversation
        ) as stream:
            print("GPT: ", end="", flush=True)
            for event in stream:  # teraz dziaÅ‚a poprawnie
                # event moÅ¼e mieÄ‡ rÃ³Å¼ne typy, interesuje nas delta tekstu
                if event.type == "response.output_text.delta":
                    print(event.delta, end="", flush=True)
                    reply_text += event.delta
    
        
        print(f"\nresponse time: {datetime.now() - timeout_start}")  # nowa linia po odpowiedzi
        conversation.append({"role": "assistant", "content": reply_text})
        

def chat_with_prompt_responses():
    print(openai.__version__)
    print("ğŸ’¬ Terminalowy czat z prompt OpenAI (Responses API)")
    print("Wpisz 'exit', aby zakoÅ„czyÄ‡.\n")
    user_input = input("Czy chcesz zaczÄ…Ä‡? (tak/nie): ")
    from openai import OpenAI
    client = OpenAI(api_key=openai.api_key)
    conversation = []  # do zachowania historii w tej sesji

    while True:
        user_input = input("Ty: ")
        if user_input.lower() == "exit":
            print("ğŸ‘‹ ZakoÅ„czono czat.")
            break

        conversation.append({"role": "user", "content": user_input})

        print("Asystent: ", end="", flush=True)
        reply_text = ""
        start = datetime.now()

        # --- Streaming nowym Responses API ---
        with client.responses.stream(
            model=MODEL,
            prompt={"id": PROMPT_ID},   # prompt = nowy odpowiednik asystenta
            input=[{"role": "user", "content": user_input}],
        ) as stream:
            for event in stream:
                if event.type == "response.output_text.delta":
                    print(event.delta, end="", flush=True)
                    reply_text += event.delta
            stream.until_done()

        print(f"\nâ± Czas odpowiedzi: {datetime.now() - start}\n")

        conversation.append({"role": "user", "content": user_input})
        conversation.append({"role": "assistant", "content": reply_text})

       

def main():
    # Diagnostic startup info (nie ujawnia sekretÃ³w) ---------------------
    import sys
    import os
    import site

    print("--- Startup diagnostic ---")
    try:
        print("executable:", sys.executable)
        print("prefix:", sys.prefix)
        print("base_prefix:", getattr(sys, "base_prefix", None))
        print("VIRTUAL_ENV:", os.environ.get("VIRTUAL_ENV"))
        in_venv = sys.prefix != getattr(sys, "base_prefix", None)
        print("in_venv:", in_venv)
        # site-packages (jeÅ›li dostÄ™pne)
        try:
            sp = site.getsitepackages()
        except Exception:
            sp = []
        print("site.getsitepackages():", sp)
        # pokaÅ¼ pierwsze wpisy sys.path, nie ujawniajÄ…c wraÅ¼liwych danych
        print("sys.path (first 6):")
        for p in sys.path[:6]:
            print("  -", p)
    except Exception as _e:
        print("Startup diagnostic error:", _e)
    print("--- End diagnostic ---\n")

    # JeÅ›li model jest starszy â€“ uÅ¼ywamy ChatCompletion, jeÅ›li nowszy â€“ Responses
    #if MODEL.startswith("gpt-3") or MODEL.startswith("gpt-4"):
    #    chat_with_prompt_responses()
    #else:
    #    #use_responses()
    chat_with_prompt_responses()

if __name__ == "__main__":
    main()

# def main():
#     print("Witaj w projekcie TestOpenAI!")
#     print(system.executable)
#     print(system.version)
#     
#     now = datetime.now()
#     print("Aktualny czas:", now.strftime("%Y-%m-%d %H:%M:%S"))
#     
#     client = OpenAI(
#         api_key=os.getenv("OPENAI_API_KEY")
#     )
#
#     response = client.responses.create(
#         model="gpt-5-mini",
#         input="PowtÃ³rz tekst: Witaj Å›wiecie"      
#     )
#
#     print(response.output_text)
#     now2 = datetime.now()
#     diff_seconds = (now2 - now).total_seconds()
#     print(f"Czas wykonania: {diff_seconds:.3f}")






