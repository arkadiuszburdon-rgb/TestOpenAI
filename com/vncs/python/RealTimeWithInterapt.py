import asyncio, json, sounddevice as sd, websockets, os, base64
from dotenv import load_dotenv
from datetime import datetime
import keyboard

#----------------------------------------------------------
# Projekt: Naturalny asystent gÅ‚osowy mÃ³wiÄ…cy po polsku.
# Odpowiada naturalnie i zwiÄ™Åºle.   
# Nie powtarza uÅ¼ytkownika â€” odpowiada sensownie.
# Detekcja mowy i zarzÄ…dzanie turami przez serwer (OpenAI Realtime API).
# Dodano przerwanie odpowiedzi asystenta, gdy uÅ¼ytkownik zaczyna mÃ³wiÄ‡ (barge-in).
#-----------------------------------------------

load_dotenv()
API_KEY = os.getenv("OPENAI_API_KEY")

MODEL = "gpt-4o-realtime-preview"
SAMPLE_RATE = 24000
CHUNK = 1024

 

SYSTEM_PROMPT = """
JesteÅ› asystentem gÅ‚osowym mÃ³wiÄ…cym po polsku.
Odpowiadaj naturalnie, zwiÄ™Åºle i przyjaÅºnie.
Nie powtarzaj uÅ¼ytkownika â€” odpowiadaj sensownie.
"""

# ğŸ”„ nadpisujemy logi przy starcie
open("events.log", "w").close()

with open("events.log", "w", encoding="utf-8") as f:
    f.write("Start logÃ³w")


def select_default_microphone():
    devices = sd.query_devices()
    default_mic_index = None

    for idx, dev in enumerate(devices):
        # Szukamy domyÅ›lnego wejÅ›cia laptopa
        if dev['max_input_channels'] > 0 and ("Microphone" in dev['name'] or "Realtek" in dev['name'] or "Internal" in dev['name']):
            default_mic_index = idx
            break

    if default_mic_index is None:
        print("âš ï¸ Nie znaleziono mikrofonu laptopa â€” uÅ¼ywam domyÅ›lnego")
        return None
    
    print(f"âœ… Wybrano mikrofon: {devices[default_mic_index]['name']}")
    sd.default.device = (None, sd.default.device[1])
    
def audio_energy(pcm_bytes):
    """Zwraca poziom RMS sygnaÅ‚u audio"""
    audio = np.frombuffer(pcm_bytes, dtype=np.int16)
    if len(audio) == 0:
         return 0
    energy = np.sqrt(np.mean(audio.astype(np.float32)**2))
    return energy

async def run():
    
    select_default_microphone()
    #sd.default.device = (None, sd.default.device[1])

    print("ğŸ¤ MÃ³w â€” nasÅ‚uchujÄ™...")

    ws = await websockets.connect(
        f"wss://api.openai.com/v1/realtime?model={MODEL}",
        extra_headers={
            "Authorization": f"Bearer {API_KEY}",
            "OpenAI-Beta": "realtime=v1"
        }
    )

    await ws.send(json.dumps({
        "type": "session.update",
        "session": {
            "instructions": SYSTEM_PROMPT,
            "modalities": ["audio", "text"],
            "input_audio_format": "pcm16",
            "output_audio_format": "pcm16",

            # âœ… tylko stabilny VAD â€” bez nieobsÅ‚ugiwanych pÃ³l
            "turn_detection": {
                "type": "server_vad",
                "threshold": 0.6,
                "prefix_padding_ms": 300,
                "silence_duration_ms": 200
            },

            "input_audio_transcription": {
                "model": "gpt-4o-transcribe",
                "language": "pl"
            }
        }
    }))

    audio_out_buffer = bytearray()
    mute_mic = True
    is_speaking = False
    
    def audio_callback(outdata, frames, time, status):
        nonlocal audio_out_buffer
        if len(audio_out_buffer) >= frames * 2:
            chunk = audio_out_buffer[:frames * 2]
            outdata[:] = chunk
            del audio_out_buffer[:frames * 2]
        else:
            outdata[:] = b'\x00' * frames * 2

    async def mic():
        nonlocal mute_mic
        with sd.RawInputStream(samplerate=SAMPLE_RATE, channels=1, dtype="int16") as stream:
            while True:
                data, _ = stream.read(CHUNK)
                pcm = bytes(data)

                if not mute_mic:
                    await ws.send(json.dumps({
                        "type": "input_audio_buffer.append",
                        "audio": base64.b64encode(pcm).decode()
                    }))
                    
                await asyncio.sleep(0)

    async def rx():
        nonlocal audio_out_buffer, mute_mic, is_speaking

        with sd.RawOutputStream(samplerate=SAMPLE_RATE, channels=1, dtype="int16", callback=audio_callback):
            async for msg in ws:

                evt = json.loads(msg)
                t = evt.get("type")

                # ğŸ“ log do pliku (pierwsze 350 znakÃ³w)
                with open("events.log", "a", encoding="utf-8") as f:
                    f.write(f"[{datetime.now()}] {json.dumps(evt, ensure_ascii=False)[:350]}\n")

                if t == "input_audio_buffer.speech_started":
                    print("\nğŸ¤ PoczÄ…tek wypowiedzi...")
                    # jeÅ›li bot mÃ³wi â†’ przerwij
                    audio_out_buffer = bytearray()  # czyÅ›cimy wyjÅ›cie audio
                    if is_speaking:
                        print("â›” Przerywam odpowiedÅº modelu â€” uÅ¼ytkownik zaczÄ…Å‚ mÃ³wiÄ‡")
                        is_speaking = False
                        # anulowanie odpowiedzi modelu
                        await ws.send(json.dumps({"type": "response.cancel"}))

                #if t == "conversation.item.input_audio_transcription.delta":
                    #print(evt.get("delta",""), end="", flush=True)

                if t == "conversation.item.input_audio_transcription.completed":
                    print(f"\nğŸ‘¤ Ty: {evt.get('transcript')}\n")
                    print("\nğŸ¤ Zakonczenie wypowiedzi")

                if t == "response.audio_transcript.delta":
                    #print(evt.get("delta",""), end="", flush=True)
                    pass

                if t == "response.audio_transcript.done":
                    is_speaking = False
                    print(evt.get("transcript",""), end="", flush=True)
                    print("\nğŸ¤– --- Koniec odpowiedzi ---\n")
                    await asyncio.sleep(1)  # pozwÃ³l dokoÅ„czyÄ‡ odtwarzanie
                
                if t == "response.audio.delta":
                    is_speaking = True
                    pcm = base64.b64decode(evt["delta"])
                    audio_out_buffer.extend(pcm)
                    
                    
    # PozwÃ³l audio-out siÄ™ wÅ‚Ä…czyÄ‡ zanim startuje mikrofon
    # Warm-up mic mute (zapobiega pierwszemu "klikniÄ™ciu")
    mute_mic = True
    await asyncio.sleep(0.35)
    mute_mic = False
    await asyncio.gather(mic(), rx())


asyncio.run(run())
